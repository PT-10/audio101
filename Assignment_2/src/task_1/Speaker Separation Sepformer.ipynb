{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/microsoft/UniSpeech.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/pytorch/fairseq.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T02:37:09.241215Z",
     "iopub.status.busy": "2025-04-07T02:37:09.240844Z",
     "iopub.status.idle": "2025-04-07T02:37:14.884718Z",
     "shell.execute_reply": "2025-04-07T02:37:14.883820Z",
     "shell.execute_reply.started": "2025-04-07T02:37:09.241189Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install --force pip==24.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T02:37:15.021332Z",
     "iopub.status.busy": "2025-04-07T02:37:15.021042Z",
     "iopub.status.idle": "2025-04-07T02:38:01.211325Z",
     "shell.execute_reply": "2025-04-07T02:38:01.210168Z",
     "shell.execute_reply.started": "2025-04-07T02:37:15.021308Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install s3prl fire omegaconf==2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T02:38:01.219001Z",
     "iopub.status.busy": "2025-04-07T02:38:01.218709Z",
     "iopub.status.idle": "2025-04-07T02:38:01.237187Z",
     "shell.execute_reply": "2025-04-07T02:38:01.236402Z",
     "shell.execute_reply.started": "2025-04-07T02:38:01.218982Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/kaggle/working/fairseq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T02:38:01.238713Z",
     "iopub.status.busy": "2025-04-07T02:38:01.238408Z",
     "iopub.status.idle": "2025-04-07T02:46:44.302076Z",
     "shell.execute_reply": "2025-04-07T02:46:44.301084Z",
     "shell.execute_reply.started": "2025-04-07T02:38:01.238686Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install --editable ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T15:50:29.715766Z",
     "iopub.status.busy": "2025-04-06T15:50:29.715539Z",
     "iopub.status.idle": "2025-04-06T15:50:38.239528Z",
     "shell.execute_reply": "2025-04-06T15:50:38.238652Z",
     "shell.execute_reply.started": "2025-04-06T15:50:29.715745Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-04-06 15:50:29--  https://mm.kaist.ac.kr/datasets/voxceleb/meta/veri_test2.txt\n",
      "Resolving mm.kaist.ac.kr (mm.kaist.ac.kr)... 143.248.39.47\n",
      "Connecting to mm.kaist.ac.kr (mm.kaist.ac.kr)|143.248.39.47|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2331882 (2.2M) [text/plain]\n",
      "Saving to: ‘veri_test2.txt’\n",
      "\n",
      "veri_test2.txt      100%[===================>]   2.22M   264KB/s    in 7.4s    \n",
      "\n",
      "2025-04-06 15:50:38 (309 KB/s) - ‘veri_test2.txt’ saved [2331882/2331882]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://mm.kaist.ac.kr/datasets/voxceleb/meta/veri_test2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T15:50:38.242364Z",
     "iopub.status.busy": "2025-04-06T15:50:38.242108Z",
     "iopub.status.idle": "2025-04-06T15:50:38.367853Z",
     "shell.execute_reply": "2025-04-06T15:50:38.367038Z",
     "shell.execute_reply.started": "2025-04-06T15:50:38.242342Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!mv /kaggle/working/fairseq/veri_test2.txt /kaggle/working/UniSpeech/downstreams/speaker_verification/veri_test2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T02:36:14.636323Z",
     "iopub.status.busy": "2025-04-07T02:36:14.636051Z",
     "iopub.status.idle": "2025-04-07T02:36:14.998748Z",
     "shell.execute_reply": "2025-04-07T02:36:14.997958Z",
     "shell.execute_reply.started": "2025-04-07T02:36:14.636304Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([0, 1, 2], dtype='int64')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv('/kaggle/working/UniSpeech/downstreams/speaker_verification/veri_test2.txt', sep=\" \", header=None)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T16:47:58.352769Z",
     "iopub.status.busy": "2025-04-06T16:47:58.352472Z",
     "iopub.status.idle": "2025-04-06T16:47:58.356616Z",
     "shell.execute_reply": "2025-04-06T16:47:58.355728Z",
     "shell.execute_reply.started": "2025-04-06T16:47:58.352747Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/kaggle/working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!python verification.py --model_name wavlm_base_plus --wav1 /kaggle/input/vox-celeb/vox_celeb/vox1/vox1_test_wav/wav/id10270/x6uYqmx31kE/00001.wav --wav2 /kaggle/input/vox-celeb/vox_celeb/vox1/vox1_test_wav/wav/id10270/8jEAjG6SegY/00008.wav --checkpoint /kaggle/input/wavelm_base_plus/pytorch/default/1/wavlm_base_plus_nofinetune.pth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T03:52:10.416908Z",
     "iopub.status.busy": "2025-04-07T03:52:10.416570Z",
     "iopub.status.idle": "2025-04-07T03:52:28.522639Z",
     "shell.execute_reply": "2025-04-07T03:52:28.521699Z",
     "shell.execute_reply.started": "2025-04-07T03:52:10.416854Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/hub.py:330: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
      "  warnings.warn(\n",
      "Downloading: \"https://github.com/s3prl/s3prl/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
      "/root/.cache/torch/hub/s3prl_s3prl_main/s3prl/upstream/byol_s/byol_a/common.py:20: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"sox_io\")\n",
      "Downloading: https://huggingface.co/s3prl/converted_ckpts/resolve/main/wavlm_base_plus.pt\n",
      "Destination: /root/.cache/s3prl/download/72cb34edf8a3724c720467cf40b77ad20b1b714b5f694e9db57f521467f9006b.wavlm_base_plus.pt\n",
      "100%|██████████| 360M/360M [00:04<00:00, 85.9MB/s] \n",
      "/root/.cache/torch/hub/s3prl_s3prl_main/s3prl/upstream/wavlm/expert.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(ckpt)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "<ipython-input-52-de47239a5d90>:290: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(checkpoint, map_location=lambda storage, loc: storage)\n"
     ]
    }
   ],
   "source": [
    "model = init_model(model_name=\"wavlm_base_plus\", checkpoint=\"/kaggle/input/wavelm_base_plus/pytorch/default/1/wavlm_base_plus_nofinetune.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speaker Separation on Mixed Dataset using Sepformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install speechbrain pydub pesq museval torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T03:06:07.152272Z",
     "iopub.status.busy": "2025-04-07T03:06:07.151832Z",
     "iopub.status.idle": "2025-04-07T03:06:07.159125Z",
     "shell.execute_reply": "2025-04-07T03:06:07.158365Z",
     "shell.execute_reply.started": "2025-04-07T03:06:07.152242Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "aac_dir = \"/kaggle/input/vox-celeb/vox2_test_aac/aac\"\n",
    "all_ids = sorted(os.listdir(aac_dir))\n",
    "train_ids = all_ids[:50]\n",
    "test_ids = all_ids[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T03:06:19.201017Z",
     "iopub.status.busy": "2025-04-07T03:06:19.200591Z",
     "iopub.status.idle": "2025-04-07T03:06:19.241851Z",
     "shell.execute_reply": "2025-04-07T03:06:19.241241Z",
     "shell.execute_reply.started": "2025-04-07T03:06:19.200985Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from pydub import AudioSegment\n",
    "from pathlib import Path\n",
    "\n",
    "def mix_utterances(speaker1_path, speaker2_path, output_path):\n",
    "    audio1 = AudioSegment.from_file(speaker1_path)\n",
    "    audio2 = AudioSegment.from_file(speaker2_path)\n",
    "\n",
    "    # Ensure same duration\n",
    "    min_len = min(len(audio1), len(audio2))\n",
    "    mixed = audio1[:min_len].overlay(audio2[:min_len])\n",
    "\n",
    "    mixed.export(output_path / \"mixture.wav\", format=\"wav\")\n",
    "    audio1[:min_len].export(output_path / \"source1.wav\", format=\"wav\")\n",
    "    audio2[:min_len].export(output_path / \"source2.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T03:56:03.526116Z",
     "iopub.status.busy": "2025-04-07T03:56:03.525683Z",
     "iopub.status.idle": "2025-04-07T03:56:03.532649Z",
     "shell.execute_reply": "2025-04-07T03:56:03.531758Z",
     "shell.execute_reply.started": "2025-04-07T03:56:03.526086Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def create_mixtures(id_list, base_dir, out_dir, num_samples=100):\n",
    "    speaker_map = {}\n",
    "    mix_idx = 0  # Ensures sequential naming for skipped mixes\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        spk1, spk2 = random.sample(id_list, 2)\n",
    "\n",
    "        spk1_files = list(Path(base_dir, spk1).rglob(\"*.m4a\"))\n",
    "        spk2_files = list(Path(base_dir, spk2).rglob(\"*.m4a\"))\n",
    "\n",
    "        if not spk1_files or not spk2_files:\n",
    "            continue  # Skip if no valid audio files\n",
    "\n",
    "        f1 = random.choice(spk1_files)\n",
    "        f2 = random.choice(spk2_files)\n",
    "\n",
    "        mix_id = f\"mix_{mix_idx}\"\n",
    "        out_path = Path(out_dir, mix_id)\n",
    "        out_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Call your mixing function (assumed defined elsewhere)\n",
    "        mix_utterances(f1, f2, out_path)\n",
    "\n",
    "        # Update speaker map\n",
    "        speaker_map[mix_id] = [spk1, spk2]\n",
    "        mix_idx += 1\n",
    "\n",
    "    # Save speaker map JSON\n",
    "    speaker_map_path = Path(out_dir) / \"test_mix_speaker_map.json\"\n",
    "    with open(speaker_map_path, \"w\") as f:\n",
    "        json.dump(speaker_map, f, indent=2)\n",
    "\n",
    "    print(f\"Created {mix_idx} mixtures and saved speaker map to {speaker_map_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T03:56:15.696722Z",
     "iopub.status.busy": "2025-04-07T03:56:15.696353Z",
     "iopub.status.idle": "2025-04-07T03:58:04.850216Z",
     "shell.execute_reply": "2025-04-07T03:58:04.849423Z",
     "shell.execute_reply.started": "2025-04-07T03:56:15.696693Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 100 mixtures and saved speaker map to /kaggle/working/train_mixes/test_mix_speaker_map.json\n",
      "Created 100 mixtures and saved speaker map to /kaggle/working/test_mixes/test_mix_speaker_map.json\n"
     ]
    }
   ],
   "source": [
    "create_mixtures(train_ids, \"/kaggle/input/vox-celeb/vox2_test_aac/aac\", \"/kaggle/working/train_mixes\")\n",
    "create_mixtures(test_ids, \"/kaggle/input/vox-celeb/vox2_test_aac/aac\", \"/kaggle/working/test_mixes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T03:28:06.894800Z",
     "iopub.status.busy": "2025-04-07T03:28:06.894426Z",
     "iopub.status.idle": "2025-04-07T03:43:29.742162Z",
     "shell.execute_reply": "2025-04-07T03:43:29.740996Z",
     "shell.execute_reply.started": "2025-04-07T03:28:06.894777Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/speechbrain/utils/checkpoints.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=device)\n",
      "100%|██████████| 100/100 [15:21<00:00,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           mix                                           SDR  \\\n",
      "count      100                                           100   \n",
      "unique     100                                           100   \n",
      "top     mix_99  [[-16.98153023043959], [-20.36353317291269]]   \n",
      "freq         1                                             1   \n",
      "\n",
      "                                                SIR  \\\n",
      "count                                           100   \n",
      "unique                                          100   \n",
      "top     [[4.165183636201211], [1.0840597732567738]]   \n",
      "freq                                              1   \n",
      "\n",
      "                                                  SAR  \\\n",
      "count                                             100   \n",
      "unique                                            100   \n",
      "top     [[-15.539044871167116], [-17.83029501124999]]   \n",
      "freq                                                1   \n",
      "\n",
      "                                           PESQ  \n",
      "count                                       100  \n",
      "unique                                      100  \n",
      "top     [1.035033106803894, 1.4314032793045044]  \n",
      "freq                                          1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from speechbrain.pretrained import SepformerSeparation as separator\n",
    "from scipy.io import wavfile\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from pesq import pesq\n",
    "import museval\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load SepFormer\n",
    "sepformer = separator.from_hparams(source=\"speechbrain/sepformer-whamr\", savedir=\"/kaggle/working/tmpdir_sepformer\")\n",
    "\n",
    "# Your test mix directory\n",
    "test_mix_root = \"/kaggle/working/test_mixes\"\n",
    "\n",
    "# Storage for results\n",
    "all_metrics = []\n",
    "\n",
    "def evaluate(ref1_path, ref2_path, sep1_path, sep2_path):\n",
    "    rate_ref, ref1 = wavfile.read(ref1_path)\n",
    "    _, ref2 = wavfile.read(ref2_path)\n",
    "    _, sep1 = wavfile.read(sep1_path)\n",
    "    _, sep2 = wavfile.read(sep2_path)\n",
    "\n",
    "    # Squeeze & align lengths\n",
    "    ref1 = ref1.squeeze()[:min(len(ref1), len(ref2), len(sep1), len(sep2))]\n",
    "    ref2 = ref2.squeeze()[:len(ref1)]\n",
    "    sep1 = sep1.squeeze()[:len(ref1)]\n",
    "    sep2 = sep2.squeeze()[:len(ref1)]\n",
    "\n",
    "    refs = np.stack([ref1, ref2], axis=0).astype(np.float32)\n",
    "    ests = np.stack([sep1, sep2], axis=0).astype(np.float32)\n",
    "\n",
    "    sdr, sir, sar, _ = museval.metrics.bss_eval_sources(refs, ests)\n",
    "\n",
    "    pesq1 = pesq(rate_ref, ref1.astype(np.int16), sep1.astype(np.int16), 'wb')\n",
    "    pesq2 = pesq(rate_ref, ref2.astype(np.int16), sep2.astype(np.int16), 'wb')\n",
    "\n",
    "    return {\n",
    "        \"SDR\": sdr.tolist(),\n",
    "        \"SIR\": sir.tolist(),\n",
    "        \"SAR\": sar.tolist(),\n",
    "        \"PESQ\": [pesq1, pesq2]\n",
    "    }\n",
    "\n",
    "# Loop through test samples\n",
    "for mix_dir in tqdm(sorted(os.listdir(test_mix_root))):\n",
    "    mix_path = os.path.join(test_mix_root, mix_dir)\n",
    "    mixture_file = os.path.join(mix_path, \"mixture.wav\")\n",
    "    source1_file = os.path.join(mix_path, \"source1.wav\")\n",
    "    source2_file = os.path.join(mix_path, \"source2.wav\")\n",
    "\n",
    "    # Resample to 8kHz if needed\n",
    "    mixture, sr = torchaudio.load(mixture_file)\n",
    "    if sr != 8000:\n",
    "        resampler = torchaudio.transforms.Resample(sr, 8000)\n",
    "        mixture = resampler(mixture)\n",
    "        torchaudio.save(mixture_file.replace(\".wav\", \"_8k.wav\"), mixture, 8000)\n",
    "        mixture_file = mixture_file.replace(\".wav\", \"_8k.wav\")\n",
    "\n",
    "    # Perform separation\n",
    "    out = sepformer.separate_file(path=mixture_file)\n",
    "    est_sources = out[0].transpose(0, 1)  # shape: [2, time]\n",
    "\n",
    "    sep1_path = os.path.join(mix_path, \"sep1.wav\")\n",
    "    sep2_path = os.path.join(mix_path, \"sep2.wav\")\n",
    "    torchaudio.save(sep1_path, est_sources[0].unsqueeze(0), 8000)\n",
    "    torchaudio.save(sep2_path, est_sources[1].unsqueeze(0), 8000)\n",
    "\n",
    "    # Evaluate\n",
    "    metrics = evaluate(source1_file, source2_file, sep1_path, sep2_path)\n",
    "    all_metrics.append({\n",
    "        \"mix\": mix_dir,\n",
    "        **metrics\n",
    "    })\n",
    "\n",
    "# Print or save results\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(all_metrics)\n",
    "print(df.describe())  # Show summary stats (mean, std, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T03:48:36.365312Z",
     "iopub.status.busy": "2025-04-07T03:48:36.364982Z",
     "iopub.status.idle": "2025-04-07T03:48:36.395262Z",
     "shell.execute_reply": "2025-04-07T03:48:36.394571Z",
     "shell.execute_reply.started": "2025-04-07T03:48:36.365288Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mix</th>\n",
       "      <th>SDR</th>\n",
       "      <th>SIR</th>\n",
       "      <th>SAR</th>\n",
       "      <th>PESQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mix_0</td>\n",
       "      <td>[[-17.069044008415528], [-19.075894028940937]]</td>\n",
       "      <td>[[2.6752860304896875], [0.5818220955975363]]</td>\n",
       "      <td>[[-15.147255625523883], [-16.299522242165526]]</td>\n",
       "      <td>[1.0247418880462646, 1.0264379978179932]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mix_1</td>\n",
       "      <td>[[-18.337136202879897], [-13.457945461510212]]</td>\n",
       "      <td>[[1.6300755293341884], [3.05708682162188]]</td>\n",
       "      <td>[[-16.021859436201428], [-11.614584925789359]]</td>\n",
       "      <td>[1.0536715984344482, 1.0284733772277832]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mix_10</td>\n",
       "      <td>[[-15.139187247421532], [-20.111132596237624]]</td>\n",
       "      <td>[[5.166741657040355], [0.029240042038632418]]</td>\n",
       "      <td>[[-13.944691368552215], [-17.07317500983563]]</td>\n",
       "      <td>[1.0532764196395874, 1.0292764902114868]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mix_11</td>\n",
       "      <td>[[-21.24172847078424], [-18.964291162477803]]</td>\n",
       "      <td>[[0.3822814849974416], [2.126926014614753]]</td>\n",
       "      <td>[[-18.388380939904827], [-16.854616881689264]]</td>\n",
       "      <td>[1.0228641033172607, 1.0225387811660767]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mix_12</td>\n",
       "      <td>[[-20.961478873540358], [-18.56597937643512]]</td>\n",
       "      <td>[[-1.0836117722560068], [1.4838763634284122]]</td>\n",
       "      <td>[[-17.330764316931273], [-16.191400666490225]]</td>\n",
       "      <td>[1.0745307207107544, 1.0445177555084229]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>mix_95</td>\n",
       "      <td>[[-22.887926256862134], [-17.8028707112885]]</td>\n",
       "      <td>[[-0.9532596572558356], [2.8820649519534]]</td>\n",
       "      <td>[[-19.34698726246016], [-15.961538827352156]]</td>\n",
       "      <td>[1.0292237997055054, 1.0773890018463135]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>mix_96</td>\n",
       "      <td>[[-19.140684863118963], [-17.847187670473037]]</td>\n",
       "      <td>[[2.640839407758043], [2.7941847598760337]]</td>\n",
       "      <td>[[-17.224182282632636], [-15.975405833827896]]</td>\n",
       "      <td>[1.256512999534607, 1.0657751560211182]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>mix_97</td>\n",
       "      <td>[[-20.76550731026028], [-19.145009551979907]]</td>\n",
       "      <td>[[-0.5534130170461288], [3.6685769006009012]]</td>\n",
       "      <td>[[-17.428134097432483], [-17.569849087999106]]</td>\n",
       "      <td>[1.025382399559021, 1.0720341205596924]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>mix_98</td>\n",
       "      <td>[[-20.35340465330187], [-17.79552302211158]]</td>\n",
       "      <td>[[0.7223739964436847], [1.1420638474621916]]</td>\n",
       "      <td>[[-17.655256138210184], [-15.262998529353855]]</td>\n",
       "      <td>[1.1043754816055298, 1.234655499458313]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>mix_99</td>\n",
       "      <td>[[-16.98153023043959], [-20.36353317291269]]</td>\n",
       "      <td>[[4.165183636201211], [1.0840597732567738]]</td>\n",
       "      <td>[[-15.539044871167116], [-17.83029501124999]]</td>\n",
       "      <td>[1.035033106803894, 1.4314032793045044]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mix                                             SDR  \\\n",
       "0    mix_0  [[-17.069044008415528], [-19.075894028940937]]   \n",
       "1    mix_1  [[-18.337136202879897], [-13.457945461510212]]   \n",
       "2   mix_10  [[-15.139187247421532], [-20.111132596237624]]   \n",
       "3   mix_11   [[-21.24172847078424], [-18.964291162477803]]   \n",
       "4   mix_12   [[-20.961478873540358], [-18.56597937643512]]   \n",
       "..     ...                                             ...   \n",
       "95  mix_95    [[-22.887926256862134], [-17.8028707112885]]   \n",
       "96  mix_96  [[-19.140684863118963], [-17.847187670473037]]   \n",
       "97  mix_97   [[-20.76550731026028], [-19.145009551979907]]   \n",
       "98  mix_98    [[-20.35340465330187], [-17.79552302211158]]   \n",
       "99  mix_99    [[-16.98153023043959], [-20.36353317291269]]   \n",
       "\n",
       "                                              SIR  \\\n",
       "0    [[2.6752860304896875], [0.5818220955975363]]   \n",
       "1      [[1.6300755293341884], [3.05708682162188]]   \n",
       "2   [[5.166741657040355], [0.029240042038632418]]   \n",
       "3     [[0.3822814849974416], [2.126926014614753]]   \n",
       "4   [[-1.0836117722560068], [1.4838763634284122]]   \n",
       "..                                            ...   \n",
       "95     [[-0.9532596572558356], [2.8820649519534]]   \n",
       "96    [[2.640839407758043], [2.7941847598760337]]   \n",
       "97  [[-0.5534130170461288], [3.6685769006009012]]   \n",
       "98   [[0.7223739964436847], [1.1420638474621916]]   \n",
       "99    [[4.165183636201211], [1.0840597732567738]]   \n",
       "\n",
       "                                               SAR  \\\n",
       "0   [[-15.147255625523883], [-16.299522242165526]]   \n",
       "1   [[-16.021859436201428], [-11.614584925789359]]   \n",
       "2    [[-13.944691368552215], [-17.07317500983563]]   \n",
       "3   [[-18.388380939904827], [-16.854616881689264]]   \n",
       "4   [[-17.330764316931273], [-16.191400666490225]]   \n",
       "..                                             ...   \n",
       "95   [[-19.34698726246016], [-15.961538827352156]]   \n",
       "96  [[-17.224182282632636], [-15.975405833827896]]   \n",
       "97  [[-17.428134097432483], [-17.569849087999106]]   \n",
       "98  [[-17.655256138210184], [-15.262998529353855]]   \n",
       "99   [[-15.539044871167116], [-17.83029501124999]]   \n",
       "\n",
       "                                        PESQ  \n",
       "0   [1.0247418880462646, 1.0264379978179932]  \n",
       "1   [1.0536715984344482, 1.0284733772277832]  \n",
       "2   [1.0532764196395874, 1.0292764902114868]  \n",
       "3   [1.0228641033172607, 1.0225387811660767]  \n",
       "4   [1.0745307207107544, 1.0445177555084229]  \n",
       "..                                       ...  \n",
       "95  [1.0292237997055054, 1.0773890018463135]  \n",
       "96   [1.256512999534607, 1.0657751560211182]  \n",
       "97   [1.025382399559021, 1.0720341205596924]  \n",
       "98   [1.1043754816055298, 1.234655499458313]  \n",
       "99   [1.035033106803894, 1.4314032793045044]  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T03:48:59.028591Z",
     "iopub.status.busy": "2025-04-07T03:48:59.028219Z",
     "iopub.status.idle": "2025-04-07T03:48:59.064086Z",
     "shell.execute_reply": "2025-04-07T03:48:59.063334Z",
     "shell.execute_reply.started": "2025-04-07T03:48:59.028563Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           PESQ_1      PESQ_2\n",
      "count  100.000000  100.000000\n",
      "mean     1.063066    1.064700\n",
      "std      0.085249    0.090504\n",
      "min      1.019078    1.017695\n",
      "25%      1.026018    1.024959\n",
      "50%      1.036226    1.034923\n",
      "75%      1.062487    1.071523\n",
      "max      1.682800    1.639908\n"
     ]
    }
   ],
   "source": [
    "# Flatten lists into columns\n",
    "df[['SDR_1', 'SDR_2']] = pd.DataFrame(df['SDR'].tolist(), index=df.index)\n",
    "df[['SIR_1', 'SIR_2']] = pd.DataFrame(df['SIR'].tolist(), index=df.index)\n",
    "df[['SAR_1', 'SAR_2']] = pd.DataFrame(df['SAR'].tolist(), index=df.index)\n",
    "df[['PESQ_1', 'PESQ_2']] = pd.DataFrame(df['PESQ'].tolist(), index=df.index)\n",
    "\n",
    "# Drop original list-columns\n",
    "df = df.drop(columns=['SDR', 'SIR', 'SAR', 'PESQ'])\n",
    "\n",
    "# Now describe again\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T03:59:50.828332Z",
     "iopub.status.busy": "2025-04-07T03:59:50.827962Z",
     "iopub.status.idle": "2025-04-07T04:00:13.869491Z",
     "shell.execute_reply": "2025-04-07T04:00:13.868537Z",
     "shell.execute_reply.started": "2025-04-07T03:59:50.828305Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/s3prl_s3prl_main\n",
      "/root/.cache/torch/hub/s3prl_s3prl_main/s3prl/upstream/wavlm/expert.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(ckpt)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "<ipython-input-52-de47239a5d90>:290: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(checkpoint, map_location=lambda storage, loc: storage)\n",
      "100%|██████████| 100/100 [00:20<00:00,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank-1 Identification Accuracy: 47.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load WavLM-based model\n",
    "model = init_model(model_name=\"wavlm_base_plus\", checkpoint=\"/kaggle/input/wavelm_base_plus/pytorch/default/1/wavlm_base_plus_nofinetune.pth\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Load audio with resampling and convert to mono\n",
    "def load_audio(path, target_sr=16000):\n",
    "    waveform, sr = torchaudio.load(path)  # [1, T] or [2, T]\n",
    "    if sr != target_sr:\n",
    "        waveform = torchaudio.transforms.Resample(orig_freq=sr, new_freq=target_sr)(waveform)\n",
    "    if waveform.shape[0] > 1:  # stereo to mono\n",
    "        waveform = waveform.mean(dim=0)\n",
    "    return waveform.squeeze(0)  # [T]\n",
    "\n",
    "# Cosine similarity between two embeddings\n",
    "def cosine_sim(a, b):\n",
    "    return F.cosine_similarity(a.unsqueeze(0), b.unsqueeze(0)).item()\n",
    "\n",
    "# Load speaker map\n",
    "with open(\"/kaggle/working/test_mixes/test_mix_speaker_map.json\", \"r\") as f:\n",
    "    speaker_map = json.load(f)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "mix_root = \"/kaggle/working/test_mixes\"\n",
    "\n",
    "for mix_id in tqdm(sorted(speaker_map.keys())):\n",
    "    mix_dir = os.path.join(mix_root, mix_id)\n",
    "    audio_paths = [\n",
    "        os.path.join(mix_dir, \"source1.wav\"),\n",
    "        os.path.join(mix_dir, \"source2.wav\"),\n",
    "        os.path.join(mix_dir, \"sep1.wav\"),\n",
    "        os.path.join(mix_dir, \"sep2.wav\")\n",
    "    ]\n",
    "\n",
    "    # Load and pad to max length\n",
    "    waveforms = [load_audio(p) for p in audio_paths]\n",
    "    max_len = max(w.shape[0] for w in waveforms)\n",
    "    padded = [F.pad(w, (0, max_len - w.shape[0])) for w in waveforms]\n",
    "    batch_tensor = torch.stack(padded).to(device)  # Shape: [4, T]\n",
    "\n",
    "    # Get embeddings\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(batch_tensor)\n",
    "        embeddings = F.normalize(embeddings, p=2, dim=1).cpu()\n",
    "\n",
    "    ref1_emb, ref2_emb, sep1_emb, sep2_emb = embeddings\n",
    "\n",
    "    # Compare embeddings\n",
    "    scores = {\n",
    "        \"sep1_ref1\": cosine_sim(sep1_emb, ref1_emb),\n",
    "        \"sep1_ref2\": cosine_sim(sep1_emb, ref2_emb),\n",
    "        \"sep2_ref1\": cosine_sim(sep2_emb, ref1_emb),\n",
    "        \"sep2_ref2\": cosine_sim(sep2_emb, ref2_emb),\n",
    "    }\n",
    "\n",
    "    # Assign speakers\n",
    "    sep1_pred = speaker_map[mix_id][0] if scores[\"sep1_ref1\"] > scores[\"sep1_ref2\"] else speaker_map[mix_id][1]\n",
    "    sep2_pred = speaker_map[mix_id][1] if scores[\"sep2_ref2\"] > scores[\"sep2_ref1\"] else speaker_map[mix_id][0]\n",
    "\n",
    "    if sep1_pred == speaker_map[mix_id][0]:\n",
    "        correct += 1\n",
    "    if sep2_pred == speaker_map[mix_id][1]:\n",
    "        correct += 1\n",
    "\n",
    "    total += 2\n",
    "\n",
    "# Final Rank-1 accuracy\n",
    "acc = correct / total\n",
    "print(f\"Rank-1 Identification Accuracy: {acc * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7065803,
     "sourceId": 11301534,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 293628,
     "modelInstanceId": 272652,
     "sourceId": 323652,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
