Never be, last time ever be? You were talking about the learning order, right? Right. So, so remind me somebody kahaan kya baat kar rahe the lakshmi? Triplate loss kar rahe the, so you keep? Haan, so I factor, we factor and then what is we have? We can learn different kinds of deep learning models to perform.This, right? Right? So we can have different kinds of models to perform this. Now this is, so we spoke about CME's network. Right? Now there are 2 things that we can do. We could have, we were talking about CME's network, kyonki ham recognition ki baat kar rahe the. Right? Then you can they are doing any kind of recognition or we are doing any kind of verification. What can we do? We can have either triple at loss or we can do CME's network is by right? And in the CME's.We were using this, we are wait sort of architectures, you have 2 images going through, or 2 data point going through in this case audio signals. So, we have 2 audio signals going through and that you are learning a shared network in order to tell whether these 2 data points that are going to the belong to the same class or do they belong to different classes. Right? This is 1 of the architectures that was working with LS TF's in which what the ded was. They took this spectrograph.Of data, utterance, now that 2 things that we can do. Ek to frame wise data leta usse? Right? Frame wise data, what we were doing? Raindra kaal ke kaam kar rahe the but frame had its own limitations. Right? So the other thing that can be done is you can work with utterances. What is utterance? Atterance is a bit longer version of frame. So frame is is time specific.Would be a 25 millisecond frame, it would be a 10 millisecond frame. Atterance is more to do with sentence formation. It can still be time specific but it is a bit longer which so that it provides your context as well and then go into the details of that a bit more. But the difference that happens is when you take utterances you get more context. You get more data to operate with and when you get more data to operate with then you can actually have better results because.Have more information that you are working with, right? So this is an example of you can the way you can work with LSTM's. So in this case what the dedh was they took a spectrogram of data references. They took this batch of features. Right. They learned embedding using LSTM and when they were learning the embedding what the dedh was they learned embedding for each case. So we are doing speaker recognition in this case and in this.Recognition you could with they they try to learn embedding for each class and then have a similarity matrix. Ok? What will that similarity matrix tell you? Similarity matrix was telling that what if you have in pairs of data will it be a positive level, it's a negative level or what is it? Right? So so what you could do is you could take a CMIs architecture, you have 2 input data points and then for every classCould have emiting slurs and from those emiting you could learn a similarity midwrids which is telling you what is the probability of what are the chances that it belongs to 1 class versus it belongs to other class right so positive negative C emiting slurs and with this you can you can learn loss functions in a way that it is using center loss or something of that so that it is trying to because it is learning and embedding for every class.Right? So when I just learning everybody for every class you can actually minimize that intra class variation. Right? So so that is what you will see in the diagram below that the c 1, c 2, c 3 it is trying to bring the the data points of 1 class together and then in 3 is the variations. So center loss and other losses that we were talking about that day it can work in this fashion. Right? So this is 1 of the architectures that you can work with for LSTM's. Right? So so this is this.Is 1 of the things, the other thing that you can do is, you can perform L 2 and. Now within speech there 2 things. A lot of previous literature, strategy to literature to exist karta tha. A lot of that is text dependent. Because you were given a past phrase. When you have given a past phrase you have to keep on iterating that only in order to be recognized or in order to access something. Right? But today that's not that I mean that is respective in the in some case. If if I have a card.In in the car if I want to say that ok so let's say I have a car which is being driven by 3 people. The 3 3 drivers who vocationally drive the car. Now when I sit in the car I I should be able to tell my car hai mg please please adjust the car according to my driver preferences. So so seat kit bhi aa gaya rahegi, mirror kahaan jaega, side mirror kahaan jaega, all of those things it should be able to.Setter based on my voice and I can say M G please set it up according to my choices. Right? And this should not be a specific very specific fast phrase. It should be able to as long as the meaning is same, I can use a combination of words in order to tell this to M G. Right? Or the second driver or the third driver who ever is driving that can't. They should be able to use their own.So I so was to convey this message, right? Earlier it was a constraint because we were using, we were just learning with the specific set of words. When order to provide more flexibility, I would like to provide this also. So so in a way do text independent verification. I could book text dependent, I could book text independent verification. What do I need to do?I need to learn now there are 2 things when you are taking a language, right? When you are taking a test, you need to ensure that it is not just learning how it is speaking those sentences. Right? What is the difference when a person is speaking those sentences rather it should also be able to learn my teachers, the teachers of the specific audio rather than only the test.We are an example, your heart something called a shortcut learning. Ok, so there is, there is, sorry, there is something in in today's ML which is called as shortcut learning is you give data, do a model.Today you are not specifying what are the features when you are learning any kind of deep model, you are not specifying what are the features. You are just giving a lot of data and the model is learning on its own. Okay? Now what happens is let's say, I am trying to differentiate between, move and move and stars. Thik hai raat mein moon aur star, saatve minute bolte hain. I am trying to differentiate between moon moon and stars. Now what I do? Let's say you live in the city, you live on campus. Thik hai?From from the same position you want variableity in moon because moon ka size can change right? Tis din mein moon ka size change hota rahega padega ghatega. Start ki positioning same hai. Tum jab data lete ho to moon ki positioning is same hai. It's not necessary that the moon ki positioning is very not the size is very but the positioning is not changing too much. Correct? But you are collected the data. Thik hai? LHP ke baahar khade hote ya hospital ke chhabbhav khade hote you guys collected the data.What will happen? Your data will have moon at 1 place, size bearing. There is a, there is a placement of stars, different types of stars and you learn ki moon ka hai, moon kaisa bhi itna us star kaisa rakhata hai? Tumne labeling karke uska moon was star to phaana scene. It's done kiya right? It also runs correctly. But let's say tomorrow when you go to some other city where this.Business change, thik hai? Meri your, your, your in America, meri your in iraas, kahin aap gae jahaan par this positioning of moon and staffs changed. Right? What I feel officer is the model mein actually miss classify star is moon moon in the. Reason? It was not learning the shape. Kyonki shape mein to vary a koi leti hai na kabhi chhota hota hai kabhi bada hota hai kabhi star ki jitna bada hota hai kabhi daayar ho jaata hai. Right? What is more?Consistent, the position. Position is the thing which is more consistent than the size. Ideally I would like to learn a page on size. Besides no variable is not that so rather than learning size my model learn the positioning is the important feature and the moment position change. Us position to jo bhi aaega model will serve predictin life. This is a classic example and not a primary catered example. People have found this half aOk, people have observed this happening that this happens. We were working, we were working with some sort of health care data, right? And the data under 1 different kind of compression. So, COVID ka data tha. We got healthiest samples from the US. Right? Because COVID the time the healthy log funds x ray karva rahe the. It was all positive people who were getting x ray done. Right? So all my health data was coming from the US.From some public repositories aur mera saara COVID ka data India saara tha. Thik hai? The data that was coming from India was coming with certain machines. Kyonki do tin hospitals se collaboration tha data vahin se aa raha tha and those machines were doing certain kind of compression, certain kind of processing on the data, ok? US ka data was doing something else but when so model 1 was giving very high Fanta,Vikaas ki rasid saakhoot ho gaya right? When we said let's roll it out. Thik hai chalo lagaate hain. So when you are ICMR testing. ICMR ne kaha we will do a full project testing par yah lo pakad ek chhota test data. Computer computer computer computer computer computer computer that's all that model went to. The trouble was vahaan par India ka data, health data as well as cobalt data was from India and.Giving a lot of false positive. Reason? Usne vah compression learn kar liya tha. Rather than learning the variations in COVID versus healthy, it was a lot more easy for the model to learn the variations between you. The way image was processed. The way image was processed compression ke jo variations the compression ke jo characteristics the versus jo india ke compression ke jo characters the indian machines. Right? So the moment healthy data from the share same machines came.So this happens. Now where was I? So so in order to ensure that your model is learning person, person embedded also. The characteristics of the individual rather than just the characteristic of the tech that has been spoken. Let say eyes being my name is richa, you speak my name is rhaansh. Right? Now tomorrow when IWant to pool I want to get access to share his ID and that tomorrow I come and say my name is share and get access to this. Because we are do variations. Right? Next plus the audio. So it should not happen that whatever I am trying to do it is it is. It is learning the other thing. If that is simpler for for some reason the other thing is simpler. Right? So that is what we try to do is can we do end to end. Expand dependent or text dependent.Returnation of speakers. So now if you do end to end and within this end to end what we can do is you are trying to identify what is the speech and you are also trying to identify what is the speaker. Now the intermediate task to be my annual call is speaker recognition but within the intermediate goal before the engine major tool I might have other things I might have I might have a model to recognize language. To them say in English I can talk to MG. MG saidPreference I for right? So so you can use different languages as well. Let's say the working with 2 languages. So you can have N 2 and model which is doing these 2 things. It is doing language prediction plus it is doing. Right? So you can have a model which is performing both of these things. Now if you have that kind of a model what happens? You need to ensure that the loss function that you are learning.The loss function, kyonki landal protection ke lie loss function puchha ho sakta hai?Speak in the mission ke lie loss function puchha ho sakta hai? Labor is obviously all different, right? So loss functions will also be multiple of them, right? So so in that case you can have a multiple of these loss functions combined together in order to be able to predict and and I'll just walk you through 1 of the examples there. So you can do this end to end, it's verification and you can do end to end, it's independent also, right? So,Then having jaise yahaan par cosine symbolize the lagaakar, so you can do this for science andality, uske oopar I am going to the largest regulation or something. Rather than having to do that, you can do complete and to end sort of a thing where oopar se largest regulation ko hataakar sidhe LSTM ke lie are saath, I can have, I can perform, apply a soft maths or a perception and do and to end, speak a verification of poora ka poora classification. Right? science and biology score aur science and biology score kya karega? So you are learning a model which is just give you a science and biology score. And which mobility score you are learning on the classes of the which is logistic regress which is giving you the classes out. So it's working in 2 stages. Right? Jaise ham pahle karte the teachers ko alag se select kar lete the teacher kaun sa use karna hai aur usko input dete the classify. So rather than doing that, do complete the. Right? So so coming back to this prem level versus athaaran's level.Verification, this is what I was I am getting same. Prem level mein kya hota hai? The speed cycles are alive you said are very fine grained love hai kyonki?Uska context par dependata hai right and in that case something that is also done is you do by direction you are going to by direction MSP. Right? So so we can do when you are doing speaker record issue. Spinker with generation your by direction why not be very very right because aage pichhe ke context of farak nahin pad raha hai itna zyaada jo content hai vah content hai but when you are doing speech of when you are doingOr any of those sort of things. In that case having a 5 direction networks can significantly help you because you can look at forward you can look at backward or other cases with pichhe vaala update. Right so so in speech.Level even here for frame level and utterance level the usage changes. When we are doing speech recognition, atarance level might have more benefit because then again you you get to see the entire sentence. Attenance level by director all of it coming together makes a lot more sense. Right? But it's it not to say that speaker recognition name nahin kar sakte. Right? Frame level par karenge but anyway.Combination of frames makes an utterance. Right? So my my frame could be of millisecond, but my otherwise would be a couple of hundred milliseconds. So may be may be 50 frames, comprise and utterance. Right? Now how will you combine the information when you go from frame to utterance? Any thoughts? Kaise karoge?Give me a question, right? How how can you combine frames? Information of frames to go to utterance. 1 thing is simple, earlier that like we talked about ki to vah basic some rule, our product rule we spoke 1 time right, multi model fusion kaise karte hain? That is why meri basic thing you can do. Attentions on mass.Baat se hi madi hai us. See there different ways of doing it. Yah tumhaara hi broad architecture ho gaya and 200 percent systems ka. Right? Which is operating it, input data sequence gaya, train mein paper teacher extraction hua and encoding year par har frame se embedding nikaalni hai aapne. Right? But then when you are going from these embedding to utterance level, what can you do? So so researches have been proposed.Kinds of methods to combine creation. Right? 1 of those is your tab layer which is marking but temporal average cooling. Right? So in temporal average cooling what we can do is whatever features you have learned from the phrase you can combine those embedding in different ways and just a normal combination of those embedding and then we pass through the last function and take in forward.Limitation of this, good part is you are able to combine info from multiple periods, right? But how kya? Limitation, problem kya hai ise? Kis layer se kaun sa teacher aa raha hai vo chaahie hamen?Thik hai. So, so loss of information bol raha hai, right? Either you you, so you would have combined information from different friends to go to an utterance in any case. Right? Now that 2 ways you can do it ya to yahaan par main embedding for combined karoon?Pradiction karke har frame par prediction karke final course ko combine karke. This did often. In the first 1 I have a joint set of embeddics. Jiske basis ka unclassification kar rahe hain combined karke embeddics ko hi combine karke. Second case mein har ek embeddic ko predict kiya uske baad information combine kar rahe hain. So there will be different kinds of information laws in both the stages. Now in this tab player what is happening is thatEvery frame is getting, every frame is getting equal with it. Correct, but every frame might not be so important in what I am saying. Right? Haan, so so is there a way that I can assign different ways to different.Prains right? So so so can can I put some sort of attention there? Some sort of attention if I am able to incorporated in that cooling, then that attention, modality, whatever attention methodology I am putting up, that can help in further improving the performance and retaining more important features. So it is nothing but a sort.Watered combination, if I talk in terms of very my fusion methodologies, it would be a wittered sort of fusion where every same is getting some kind of weightage based on content kya hai or uniqueness care hai uski. Haan, right. So, so that, that is a difference between your taap player and your self attempt pooling. These are 2 methods that, that were proposed and then there lot of exchange.Of these that can also be proposed. Thik hai? Another thing that you can do is in sab koi lekar jo bhi dvaare har embedding ke features aa rahe hain unko lekar you can do some sort of class serving or mega codebook out of it and then perform other kinds of processing on that. Right? So so there are other methodologies that have been that have been proposed in this case and the paper that is listed there that paper has details of all of these.Take a look at that we, kya kar raha hai? So essentially then we are learning different ways for different frames and and again those waves could be unique to different in the research. Right? For me different references or different frames can I different ways versus for some other text that I'm speaking that during that text some of the friends can have different. Right? So, so then you get all of these flexibilities that you can import for it while learning.Right? So so then going from frame to aterace. Right? Now these are some of the advancements that have been proposed and speak the recognition with your LSTM's and all, but other thing that we we discussed about close and an open set. Right? All of these variations can be applied to close set and an open set.Close at a local side with different types of loss functions. The interest in that people observe is you take a loss function. Poverterals something I don't know.Final 5 se naukri cross centropid nahin chalega aur kis par nahin chalega? Koi nahin laagoo rupandaar?Life you discussed in the last class open said does it only require when you are doing, when you are doing verification, identification, recognition. To kya karna you just need to choose the closest class. It will give you a ranking or salt. You just need to choose the closest class. So what you have to deal with is this inter class of the class kuchh karke bring it to the closest class. Tumhaara thoda chandrobi work kartega right but when we are doing this open set the other thing that we have to deal with.Is discrimination kitna hai? Right? between different classes discrimination kitna hai or se mulaabhi ki tithi. It is not that any kind of shorting I can perform the top shorting ki correct or assign ho jaega. Going from closer to of the set the second thing that is required is applying a threshold and applying a threshold is required because I need to tell you the best him at is the correct match or not or this person doesn'tData se to all right so it's not just that there is the output as an ID like you would see in the first figure the output is just an ID rather an open set you have 2 teachers you match the output is a minority value and then you have to make a decision on that's a minority value right threshold allow the yah IDs aaie ki nahin or database mein hai actually right so you have to make that additional distinction.To cross end copy basic cross end copy does not work for opency. So you have to have some better loss functions for that specific. Right? And it's it's an interesting and comparatively less exposure research area in case in any kind of technician to open set nahin karte zyaada le. What come look at them. Right? When you come to vision community also known as your 0 short sort of learn. Right? 0 short mein hi karteSaamphas nahin hai class dekh hi nahin hai to kaise bataoge. Now vision comparative hai zara short lagaane ke alaag alag taarikh hai. Right? But those those methodologies are difficult to deploy in a problem, life speaker recognition because here you are dealing with classes. You are dealing with individual. So naya individual ka kaise assign kar doge if you don't know the argument. What you can do with open set if you don't have the labels over a period of time please.You you get hundred query samples out of those hundred query samples 10 of those youReqired these are like these don't exist in my data set, right? But what you can do over a period of time is cluster these ones. Right? cluster these ones in the sense that yes, does may say you feel a cluster. Yes, do a cluster, baaki a paanch laakh laakh. Right? And then you can try to find a mapping if data set permits or if you have new classes available with you.You can try to find a kiski mapping hai, but just given that yah dvaara data set ho rahi hai to very sample saare. Al limited data set and some query samples at best you what you can do is these don't exist in the data set and then over a period of time perform a mapping of the unknown classes. These these these are multiple query samples, belonging to the same class. Right? Now in this case what people have done for open seaterlocation.Is that with your cross centrophy or with your central loss. So so you can do both of those. So, cross centrophy is there. Tomorrow basic class prediction is there. Along with that, we can also add a central loss or some other loss. The part, some sort of matric la rahi hoon. The triplet loss the baat kabhae the ramesh ji baat. So we can perform some sort of matric la rahi hoon. Now what is matric la rahi hoon? Have you heard of matric la rahi hoon?Medicline is mine, ok. Can you tell me what it means from the name itself? Name is very representative of what it does. Teacher learning kya hoti hai? Ijjilaan karte ho. Metric learning mein kya hai? Metric learning mein karte ho. Now what do I mean by metric? Metric, in this case is like a loss function, loss function itself, right? So cross antaropi was your loss function?Right, cross interview was trying to learn a space where your samples are separable, right? But not every problem like you guys said is as simple as cross interview. Right? So in in order to learn better features, what we came up with? We came up with something called the striplet laws. What was striplet laws?Ek positive ho jaata hai na? Ek negative hota hai. Thik hai? Aur inke triplet banaate learn karte the positive negative banaate learn karte the. What was that doing? That is a kind of metropolis. Right? Yah jo mera triplet lost hai triplet lost mein sab kind of a metropolis. Right? LDA jo hai mera. LDA kya karte hain? What is LDA?Disturment analysis, basically in the instrument analysis. What does it do? It tries to learn some sort of a projection. It's like it's like some sort of a projection jahaan tumhaare. Interest in the area within class experience or between class experience zeta tha unka ratio tumhaara main EMI check milta hai. Right? So so similar call sir, coming back here not as a as between class within class. Various part in some in terms of some other.Functions, some other laws functions, right? So so what you can do when you're going from close set identification to open set identification. You can you can perform this pairwise losses as a contrasted loss hai tumhaara ya triple cost hai. Kisko add kar sakte hain? Right? So have a minus percent of the plus and plus. So the loss function that you are learning is a combination. So it is this group of people as well as it is learning jo tumhaara basic laws function tha. Right? Now metric learning, metric learning.Good but matlabling mein problem kya hai? Ok, so around 20 15 20 16 to 20 20 or so, matlab learning was very very popular. Right? There are like thousands of papers that have come in matlab learning, hard mining, different sort of loss functions as well. Right? So so you did your last function? I have passed a loss to play clause, sphere place, sphere clause, angular clause. Right? Your word of angular clause?Striolos nahin gai yah permission model nahin hai yah abhi bhi CNL hai. I know the laws, real face, we know it's all your CNL's. Right? So what did us trying to do is binary cross interface tomorrow embedding is to operate karta tha in the euclidean space. Right? So rather than ready operating with just your cross interface or values in the euclidean space.These last functions what they are trying to do is they are trying to in power for it and the logic. To science and reality and the legal of that, right? To science and reality was very popular. To science and reality and the local. So can you use that method and device laws functions with the concept of in the class and in. So, so combine in those concepts. Thik hai?Centralism ka sirph ham probability dekh rahe the. Ham distances dekh rahe the abhi ham andos andos andos andos ke saath between class or between class dekhate the. Right? So so that would be some sort of a combination of software class and center class. The question that is written in the slide. Right? That's a combination of software and center class. I know there is no end to loss functions. People have designed very very interesting and sophisticated loss functions.So what will do I will I will I will not a few papers that have actually proposed these last 1. So there is an adult case, the laws then the purpose the laws it was specific to faces. Right? But there are very nice geometric interpretation to it and the last 1 can be applied to any of the. What ever classification you are doing you can be applied to any of those questions. Right? So so these are some of the.Concept some last functions that exist for better learning the embedding space. Right? And all of these again these all of these have been proposed with the respect to vision first. Yah sab computer vision mein propose hua tha vahaan se hamne utha ke audio mila tha. Right? And you can always create various ways for for audio or for other other problem states.Yes that that we are interested in right so, so these are some of the variations that you have for loss functions. Right and then another thing that you can do is, obviously, you can take a form, you can take statistical learning, you can take deep learning, combined with. So, also random deep features of source. Right? People have done this as well.Right, so I will not put too much emphasis on this, but these are some of the advancements that have been done with respect to, to see an issue, to be providing models with respect to that. Right? Now you can do and again this is a lot of this is with respect to speaker recognition. But but like I said earlier, if you combine multiple tasks speaker recognition mein. Right?So why why do I speak of a mission? I am also doing transiting. So, racha for the this this, right? Student ABC's for this this, so so, so, na any kind of television show that you are, youWe update translate karte ho to transfer chalne ki aata hai. Exaata islie singhate the, right? So rather than doing that just text can I do? Transcribing? Plus the correct admission. So then I can write which are, if you see, person 1 person 2 person 3. Right? What other things you can do? Anything that you would that you would write anything else that you would like to see.So what do we have? We have speaker recognition, we have ASR, emotion kar sakte hain. Anything else? Other thing is language, right? So let's say that you are doing transcribing and what am I doing right now? I am using a combination of Indian language. I mean hindi bolte hain to English. Right? So if you do language technician and doYes sir, right? Along with the yes sir, if I can do language recognition, won't your translation be better? It's jahaan if I if I have to transcribe my arts sentences in English? These are the words that are coming in Indian let me translate these is a hindi, right? So let me translate these to English and then do the complete transiting. So what do I have? So I have an an audio as in.Audio is input, I have a network and I have t 2 t 3 in 4 different tasks. Right? With this side you do these classes 2 1, 2 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,Like se if it is a 20 year deep network, what will it do? After the certain number of players, it will give me some output. Aapko to certain number of players, language information, I will share a charge hoga, language information hoga, phir iski correct admission hoga. Right? And all of it will be the 2 ichchha tha. Pahle aisa karoge aur dependency hai. Right? It has to be dependency ki ek ke bhinn doosra nahin hoga.Right, the the effectiveness of 1 loss or effectiveness of 1 task will be remove the other task. Right? So agar main agar main aasaan mein remove, but aasaan will perform se kharaab aage. To jo mere line mein click admission hai, uski performance ki automatic click kharaab hogi. Right?Some of the things generally there is a dependence. Because tomorrow features us hisaab's class. There are good middle of independent features. But what we are doing is these are all into an learning. Yah individual learning nahin ho rahi hai. So all of these networks that when we say a multitask learned. It's a single network which is performed all of these multiple tasks together. Right? So emotion bhi tumhaara usi mein incorporated ho raha hai pahle.Uske hisaab se emotion se, emotions pahle karna hai baat karne jo bhi karna hai. Right? So, depending on, so depending on what are the tasks you are doing for each of these tasks, there will be laws functions. Right? So there will be laws functions. So, so how can you help me in any any other life or else?Yahaan par to baat hai do laws function se, what are the do laws function?Training data hai? Loss function sir? Model, badha. Abhi train kya se karogeRight so you can assign different signings for beds to these plus functions. Let me let me show you 1 thing I think a.Old students, the old PhD student, various people like for whom, TV is the thesis. So, ok, I think online students are not able to see this.What I am trying to show you here is, on in students can you see a PDF? But it is browser,It is browsing, it is browsing. You can browse it on your own, you will try to find this if your net is faster. Bhrasht schedule task, this is the paper, draft schedule task, mitigating negative transfer in multi task learning using dynamic task dropping. So what akash tried to do is we are talking about, we are talking about having multiple loss functions together and then training a single model. Right?What are the other things you can do? Just waiting sometimes it will, sometimes it has been. Right? And and this is not a very, you might think that this is a very high statistical network, world class learning and network that I am talking about. But if you come to problems like face recognition, it's a very very very common thing. Right? For example, agar face recognition carbon, what are the different tasks that you would do?Guys ok I will send you the link guys kuchh to yah kahaani kar raha hai so let me come back to slides it's not opening. Jahaan ke mera slide.Ok, slide is visible to you guys online? Yes ma'am. And aap saanskrt. Ok, so what I was saying was, give this last chance, right? Priced admission to example I was saying. What would be the different task if you want to create a Priced admission like you?Image, let me image of this class. What will be the first step? Detect the face, localization. Localizing the region of interest, that will be the first thing. So there are 15 cases in the class. Right? So detecting these 15 cases. So that is the first step that becomes my even. Uske pahle kuchh karna hai? Uske pahle quality assistance kar sakte hain? Is the image goodRight? So, let's say my tea my tea, for the day assessment, right? My tea the is, is localization. What about the tea li? Let's say if you want to do expression recognition, post variation any of those sort of thing. Right? Iski pranjal hai ki nahin hai?Ek question likha hai. And might be by who is? Aapne to wish? To paanch cars. And this is actually very very problem to take for any person recognition system you have to do this. Thik hai?ose recognition ho sakta hai.Ka jo output hoga. See this is the another thing I think you have to see. When you are doing audio, mera input nai change ho raha tha. The entire thing was going. Mera ek audio sample tha. Us audio sample poora poora ja raha tha mera. Speaker rekha nashanta. Prem mein se prem separate ho ke poora poore saal ke saare frames were going. Right? But in this case what we were doing with these things we are going to just looking even split ki now once you are done localization. Then I don't need to background data.Because better and better and better and better and better. Only to the techie parties going for it. So every loss function. How are you learning every loss function? Right? Agar paisa technical nahin hoga to recognition obviously nahin sir. Right? So what is the importance of those loss functions and how do you actually learn them together? Basic waiting is a simple thing. You can have a combination of things but then you actually sit down to implement some of these.Multita learning will work on us then how do you want to be able to and there's a lot of new answer again.Learning is an area, a paarandah minute itself. I will share the paper with you, go through the paper. Sommetian PML are a few years apart, but very very relevant and very interesting observation. Step connections, you draw skip connections. Right? Based on the concept of skip connections, we we prefer something called as skip tasks. Drop out and drop out. Right? Drop out. Very counter intuitive.But it helps, it helps train the model better, right? Similarly, if you have 5 tasks, in the middle what you can do is we we actually drop the few tasks. So for some interventions when you are learning for some reports you can actually drop a few tasks and then come back to learn. Right over over number of reports, we assign different ways. Have some of these regularizer in place. That helps you in.The last something is learning the model better. Right? So so that is again, both through the paper there are some in some interest in observations there. But but when you have multiple of these how do you actually go ahead and combined these last functions to create and into and right? So so that is something that speaker recognition community is currently working on. Right? Because transcribing and personal recognition and all of that.Really important, right? Then there are transformers these bird models, disperd, there are lot of other models that are that are being proposed and manned class will try to go into some of these details as to how these models work. Right? But before going into that, the multiple things that we talk about right? So multiple sources of information would be there also. Multiple multiple tasks done here right? Now other thing that can be done is what if you have multiple sources of information? What do II have a video that has given a say. Right? Friends ki series chal rahi hai? Right sir video is given a say. What they have to do? You have to do this. Try is fine. Right? Kaun banda hai? Kaun kya bol rahe ho? Kaise karoge? Video aur audio ki stream alag kar denge? Every video ka hamaare tray alag karoge? Audio ko trial type karoge, video ko trial type karoge, video ko trial type karoge, time syncOk. Nahin kis kis frame se kaun sa banda tha ya kiski audio ke samay chori, iski correct mention kar lenge ya ehsaat kar rahi hoon. Thik hai? The trial's setting ho gai. Right? But what if you are you trained a multi model data, you trained a multi model network using models of using data to into modality.Face and audio, right? But during query time, you did not have access to both the parts. Sorry, you did not have access to both the data. You just had audio, you did not have audio or you just have video, you did not have audio. Right? And something we done about it.Let's say audio have video hai. Look at the the I come is going off the bottom. So you have to in the in the in the right and side with the guys. Right? Can I do this that just based on a single query input. Can I read construct both. Abhi lag jao order samudaim. If you if you take a look at the table that is on the left.Karti hai? Audio input hai? Audio input hai. Thik hai? Supervised training karenge? Audio output hai. Audio input hai video output hai. Soorted this is what you have been doing so far? Multi model feature mein kya karte hain? Audio plus video input tha, audio plus video query thi in donon ke basis ne kuchh prediction kiya mainne. Jab fusion vagairah kar rahe the frames, right that is my multi model feature.Modality learning. So audio plus video hai. So guys training ki video par testing ki video par. To input mein donon hai aur main learning sirph ek pe kar rahi hoon. Thik hai chalo kar lenge. I am I am wasting 1 resource ko baat kar lenge. Right? There is another concept of learning which is called as a shared representation. What the shared representation learning say is if you have audio and video as your you have learned the features with bothYou and video. Can you perform testing just based on video and just based on. Network ek hi trend kie do alag alag network mein kie. Agar do alag alag network kie to to koi problem kie. Kinko taega to vah alag network activate kar denge kaam karoongi. Right? Par agar single network aa raha hai, single data call, haan single data call aa raha hai, single mode alag par rukie. Then what can you do?Learnings so this is something that was performed I think as I used to have in 11 and 20 25 CML ka pick for you right multi model debloody and this is where you proposed by model important and what this said was they said you have this audio in video you can learn a share in the representation from them they have this often recorded train you can learn a share representation and from this share representation when you actually defaultEncoding the time to be learned a shareter presentation, but when from this encoding when you are actually recording, then they are able to record both a audio and video. So learn a shareter presentation in a way that you are able to record both. So when you when you perform this kind of learning, when even when you have you have this is shareter presentation or you have single modularity for data, you can perform the tasks that you are actually interested in.So he, he kind of proposed this kind of a concept of multi model and all has been existing for, for a very long time. Right? In non deep learning, learning every other thing has been existing. There was this new concept that came up in which they proposed this shared representation learning that even in absence of 1, even in the single network train, even in absence of 1 data from 1 domain you can perform whatever task you are interested in perform.Ok? So so that is your multiple sources of information learning and if you take the look at it in your apps. The video and audio. It can help you perform better in tasks like transcribing at all. Right? Because you can do lip syncing or you can take data of lip syncing and other sort of things and perform better speaker recognition or transcribing jo bhi karne mein interested ho. If you have multiple sources of inputs with you.Performing the task or yeah it it helps in better performing the task. Right? For example, if you have this kind of example that I was saying both audio or visual input at the first. So, multi model networks people have made this multi multi model networks where you can combine data from multiple modalities and again when you combine data from multiple realities how can you combine data?Provide to a single combined network. Right? You can perform this or you can perform jo kaam vahaan pahle kar rahe the. That have the features trained separately, extracted separately, what work together. What is the other thing that you can do? Other thing that we did frame based learning jaise kar rahe the. Yah process each frame separately and then combine information that you have learnt from different sources of information. Right? So so all of these.Different sort of things can be performed and people have tried this not only in this vision and all but also in, particularly the audio. Because video and audio because of very integrated input that you can get. Video are the video ke saath audio all jaata hai. Right? So this is a this is a very interestingly integrated input that you get. So you can train both of these modalities together. We it email and then it's track the information together.Of query, it might be possible that you just got a query sample from telephone. Right? Tumne kisi, tumne coin se database banaakar person with confirmation based on face and all your donon ka rakhata hai. But the query that you got was just an image. Right? So, we should be able to recognize just based on that image what is the output that we are getting. Right? So that is what you have shared ratters and patient in.Right, so so yeah these are the kinds of things that have been performed and speaker recognition. Well and speaker recognition care. Just in 1 day's class we'll do. Just this self supervise models, transform some of these sort of things and we can be landed there. Right? But 1, any questions students online before I go into the other topic?Nothing. Okay, so if there are no other questions, let me ask you 2 things. There were, I wanted to take an extra class tomorrow, sometimes.