{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchaudio librosa scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-02T11:21:43.039421Z",
     "iopub.status.busy": "2025-02-02T11:21:43.039142Z",
     "iopub.status.idle": "2025-02-02T11:21:43.059397Z",
     "shell.execute_reply": "2025-02-02T11:21:43.058459Z",
     "shell.execute_reply.started": "2025-02-02T11:21:43.039399Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import librosa\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Custom Dataset Class for UrbanSound8K\n",
    "class UrbanSound8KDataset(Dataset):\n",
    "    def __init__(self, audio_dir, file, sample_rate=22050, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            audio_dir (str): Path to the directory containing audio files.\n",
    "            file (str): Path to the CSV file containing metadata (with fsID, classID, etc.).\n",
    "            sample_rate (int): The sample rate to resample audio to (default is 22050).\n",
    "            transform (callable, optional): A function/transform to apply to the audio (e.g., MFCC).\n",
    "        \"\"\"\n",
    "        self.audio_dir = audio_dir\n",
    "        self.metadata = pd.read_csv('/kaggle/input/urbansound8k/UrbanSound8K.csv')\n",
    "        self.sample_rate = sample_rate\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Label encoding for classID to numerical labels\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.metadata['classID'] = self.label_encoder.fit_transform(self.metadata['class'])\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the total number of samples in the dataset.\"\"\"\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def extract_features(self, X):\n",
    "        result = np.array([])\n",
    "\n",
    "        # MFCC\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=self.sample_rate, n_mfcc=40).T, axis=0)\n",
    "        result = np.hstack((result, mfccs))\n",
    "\n",
    "        # Chroma_STFT\n",
    "        stft = np.abs(librosa.stft(X))\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=self.sample_rate, n_chroma=32, window=\"hamming\", n_fft=1024).T, axis=0)\n",
    "        result = np.hstack((result, chroma))\n",
    "\n",
    "        # Mel Spectrogram\n",
    "        mel = np.mean(librosa.feature.melspectrogram(y=X, sr=self.sample_rate, n_mels=128, fmax=8000, n_fft=1024, hop_length=512, window=\"hamming\").T, axis=0)\n",
    "        result = np.hstack((result, mel))\n",
    "\n",
    "        # Zero Crossing Rate\n",
    "        Z = np.mean(librosa.feature.zero_crossing_rate(y=X), axis=1)\n",
    "        result = np.hstack((result, Z))\n",
    "\n",
    "        # Root Mean Square Energy\n",
    "        rms = np.mean(librosa.feature.rms(y=X).T, axis=0)\n",
    "        result = np.hstack((result, rms))\n",
    "\n",
    "        return result\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Return the sample (audio, label, metadata) at index `idx`.\"\"\"\n",
    "        # Get the metadata for the current sample\n",
    "        row = self.metadata.iloc[idx]\n",
    "        start_time = row['start']\n",
    "        end_time = row['end']\n",
    "        fold = row['fold']\n",
    "        file_name = row['slice_file_name']\n",
    "        label = row['classID']\n",
    "        \n",
    "        # Load the audio file using librosa\n",
    "        audio_path = os.path.join(self.audio_dir, f\"fold{fold}\", file_name)\n",
    "        waveform, sample_rate = librosa.load(audio_path, sr=self.sample_rate)\n",
    "        \n",
    "        # Resample if the sample rate does not match the desired rate\n",
    "        if sample_rate != self.sample_rate:\n",
    "            waveform = librosa.resample(waveform, sample_rate, self.sample_rate)\n",
    "        \n",
    "        # Extract features\n",
    "        features = self.extract_features(waveform)\n",
    "        \n",
    "        # Convert features to tensor and label to long\n",
    "        features_tensor = torch.tensor(features, dtype=torch.float32)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)  # Ensure label is of type long\n",
    "\n",
    "        sample = {\n",
    "            'features': features_tensor,\n",
    "            'start': start_time,\n",
    "            'end': end_time,\n",
    "            'fold': fold,\n",
    "            'file_name': file_name,\n",
    "            'label': label_tensor\n",
    "        }\n",
    "        \n",
    "        return sample\n",
    "\n",
    "\n",
    "\n",
    "class AudioClassifierANN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(AudioClassifierANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)  # Raw logits, no softmax here\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)  # Raw logits\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# Create function to split dataset into train, validation, and test sets\n",
    "def create_datasets(audio_dir, file, test_size=0.2, val_size=0.2):\n",
    "    dataset = UrbanSound8KDataset(audio_dir=audio_dir, file=file)\n",
    "    \n",
    "    # Splitting the data into train, validation, and test sets\n",
    "    train_metadata, temp_metadata = train_test_split(dataset.metadata, test_size=test_size + val_size, stratify=dataset.metadata['classID'])\n",
    "    val_metadata, test_metadata = train_test_split(temp_metadata, test_size=test_size / (test_size + val_size), stratify=temp_metadata['classID'])\n",
    "    \n",
    "    # Create Dataset instances for train, validation, and test\n",
    "    train_dataset = UrbanSound8KDataset(audio_dir=audio_dir, file=train_metadata)\n",
    "    val_dataset = UrbanSound8KDataset(audio_dir=audio_dir, file=val_metadata)\n",
    "    test_dataset = UrbanSound8KDataset(audio_dir=audio_dir, file=test_metadata)\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "\n",
    "# Create DataLoaders for train, validation, and test datasets\n",
    "def create_dataloaders(train_dataset, val_dataset, test_dataset, batch_size=16):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    print(\"Starting training for the epoch...\")\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "\n",
    "    # Initialize tqdm for progress bar\n",
    "    with tqdm(train_loader, desc=\"Training\", unit=\"batch\", ncols=100) as pbar:\n",
    "        for batch in pbar:\n",
    "            features = batch['features'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            # Flatten features for input to the ANN (if necessary)\n",
    "            features = features.view(features.size(0), -1)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(features)\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_preds += labels.size(0)\n",
    "            correct_preds += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update progress bar with current loss and accuracy\n",
    "            avg_loss = running_loss / (pbar.n + 1)  # Average loss till now\n",
    "            accuracy = (correct_preds / total_preds) * 100\n",
    "            pbar.set_postfix(loss=avg_loss, accuracy=accuracy)\n",
    "\n",
    "    # Return epoch's average loss and accuracy\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    accuracy = correct_preds / total_preds * 100\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "# Define testing/validation function\n",
    "def test(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            features = batch['features'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            # Flatten features for input to the ANN (if necessary)\n",
    "            features = features.view(features.size(0), -1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(features)\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_preds += labels.size(0)\n",
    "            correct_preds += (predicted == labels).sum().item()\n",
    "\n",
    "    # Print statistics\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    accuracy = correct_preds / total_preds * 100\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T09:37:04.837063Z",
     "iopub.status.busy": "2025-02-02T09:37:04.836733Z",
     "iopub.status.idle": "2025-02-02T11:14:01.187188Z",
     "shell.execute_reply": "2025-02-02T11:14:01.185502Z",
     "shell.execute_reply.started": "2025-02-02T09:37:04.837037Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Starting training for the epoch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|█▉                     | 47/546 [01:22<11:22,  1.37s/batch, accuracy=25.4, loss=2.22]/usr/local/lib/python3.10/dist-packages/librosa/core/pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n",
      "Training:  22%|█████▏                  | 119/546 [03:05<10:15,  1.44s/batch, accuracy=37, loss=1.89]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "Training:  93%|████████████████████▍ | 507/546 [12:08<00:55,  1.42s/batch, accuracy=54.2, loss=1.35]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1103\n",
      "  warnings.warn(\n",
      "Training:  99%|█████████████████████▋| 539/546 [12:52<00:09,  1.38s/batch, accuracy=54.9, loss=1.33]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1523\n",
      "  warnings.warn(\n",
      "Training: 100%|████████████████████████| 546/546 [13:01<00:00,  1.43s/batch, accuracy=55, loss=1.33]\n",
      "<ipython-input-1-a6abbe083fe2>:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(batch['label']).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 1.3291, Train Accuracy: 54.98%, Val Loss: 1.0251, Val Accuracy: 66.23%\n",
      "Saved best model with Val Accuracy: 66.23%\n",
      "Starting training for the epoch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████| 546/546 [09:19<00:00,  1.02s/batch, accuracy=73, loss=0.833]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 0.8335, Train Accuracy: 72.96%, Val Loss: 0.6512, Val Accuracy: 79.82%\n",
      "Saved best model with Val Accuracy: 79.82%\n",
      "Starting training for the epoch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████| 546/546 [09:19<00:00,  1.02s/batch, accuracy=79.9, loss=0.624]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.6238, Train Accuracy: 79.88%, Val Loss: 0.4886, Val Accuracy: 84.05%\n",
      "Saved best model with Val Accuracy: 84.05%\n",
      "Starting training for the epoch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████| 546/546 [09:20<00:00,  1.03s/batch, accuracy=83.7, loss=0.498]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.4983, Train Accuracy: 83.68%, Val Loss: 0.4311, Val Accuracy: 85.52%\n",
      "Saved best model with Val Accuracy: 85.52%\n",
      "Starting training for the epoch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████| 546/546 [09:17<00:00,  1.02s/batch, accuracy=86.2, loss=0.412]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.4120, Train Accuracy: 86.21%, Val Loss: 0.3441, Val Accuracy: 88.67%\n",
      "Saved best model with Val Accuracy: 88.67%\n",
      "Starting training for the epoch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▍                     | 11/546 [00:12<10:03,  1.13s/batch, accuracy=88.1, loss=0.298]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c285c56a5a98>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-a6abbe083fe2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;31m# Initialize tqdm for progress bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-a6abbe083fe2>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;31m# Extract features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaveform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# Convert features to tensor and label to long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-a6abbe083fe2>\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# MFCC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mmfccs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mfcc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmfccs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/feature/spectral.py\u001b[0m in \u001b[0;36mmfcc\u001b[0;34m(y, sr, S, n_mfcc, dct_type, norm, lifter, **kwargs)\u001b[0m\n\u001b[1;32m   1987\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mS\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1988\u001b[0m         \u001b[0;31m# multichannel behavior may be different due to relative noise floor differences between channels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1989\u001b[0;31m         \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpower_to_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmelspectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1991\u001b[0m     M: np.ndarray = scipy.fftpack.dct(S, axis=-2, type=dct_type, norm=norm)[\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/feature/spectral.py\u001b[0m in \u001b[0;36mmelspectrogram\u001b[0;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[1;32m   2128\u001b[0m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Mel-frequency spectrogram'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2129\u001b[0m     \"\"\"\n\u001b[0;32m-> 2130\u001b[0;31m     S, n_fft = _spectrogram(\n\u001b[0m\u001b[1;32m   2131\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m         \u001b[0mS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py\u001b[0m in \u001b[0;36m_spectrogram\u001b[0;34m(y, S, n_fft, hop_length, power, win_length, window, center, pad_mode)\u001b[0m\n\u001b[1;32m   2942\u001b[0m             )\n\u001b[1;32m   2943\u001b[0m         S = (\n\u001b[0;32m-> 2944\u001b[0;31m             np.abs(\n\u001b[0m\u001b[1;32m   2945\u001b[0m                 stft(\n\u001b[1;32m   2946\u001b[0m                     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Load datasets and DataLoaders\n",
    "    audio_dir = '/kaggle/input/urbansound8k'\n",
    "    file = '/kaggle/input/urbansound8k/UrbanSound8K.csv'\n",
    "\n",
    "    # Split dataset into train, validation, and test sets\n",
    "    train_dataset, val_dataset, test_dataset = create_datasets(audio_dir, file)\n",
    "\n",
    "    # Create DataLoaders for each set\n",
    "    train_loader, val_loader, test_loader = create_dataloaders(train_dataset, val_dataset, test_dataset)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "\n",
    "    # Initialize model, loss function, and optimizer\n",
    "    input_size = 40 + 32 + 128 + 1 + 1  # Features for MFCC, Chroma, Mel, ZCR, RMS\n",
    "    num_classes = len(train_dataset.label_encoder.classes_)  # Number of sound classes\n",
    "    model = AudioClassifierANN(input_size=input_size, num_classes=num_classes).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Initialize best validation accuracy and model checkpoint\n",
    "    best_val_acc = 0.0\n",
    "    best_model_path = '/kaggle/working/best_model.pth'  # Path where the best model will be saved\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_acc = test(model, val_loader, criterion, device)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.2f}%')\n",
    "\n",
    "        # Save the model if it has better validation accuracy\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f'Saved best model with Val Accuracy: {val_acc:.2f}%')\n",
    "\n",
    "    # Load the best model for final evaluation\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    model.to(device)\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    test_loss, test_acc = test(model, test_loader, criterion, device)\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hamming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T11:21:49.181789Z",
     "iopub.status.busy": "2025-02-02T11:21:49.181484Z",
     "iopub.status.idle": "2025-02-02T13:04:10.213853Z",
     "shell.execute_reply": "2025-02-02T13:04:10.212820Z",
     "shell.execute_reply.started": "2025-02-02T11:21:49.181763Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Starting training for the epoch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|█▉                     | 47/546 [00:47<08:50,  1.06s/batch, accuracy=23.3, loss=2.22]/usr/local/lib/python3.10/dist-packages/librosa/core/pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n",
      "Training:  42%|█████████▏            | 227/546 [03:55<05:36,  1.06s/batch, accuracy=44.1, loss=1.65]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1103\n",
      "  warnings.warn(\n",
      "Training:  63%|██████████████▍        | 343/546 [05:55<03:27,  1.02s/batch, accuracy=49.8, loss=1.5]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1523\n",
      "  warnings.warn(\n",
      "Training:  85%|██████████████████▌   | 462/546 [07:58<01:31,  1.09s/batch, accuracy=53.6, loss=1.39]/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "Training: 100%|██████████████████████| 546/546 [09:24<00:00,  1.03s/batch, accuracy=55.8, loss=1.32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 1.3210, Train Accuracy: 55.78%, Val Loss: 0.8546, Val Accuracy: 72.34%\n",
      "Saved best model with Val Accuracy: 72.34%\n",
      "Starting training for the epoch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████| 546/546 [09:23<00:00,  1.03s/batch, accuracy=73, loss=0.817]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Train Loss: 0.8169, Train Accuracy: 72.96%, Val Loss: 0.6706, Val Accuracy: 79.29%\n",
      "Saved best model with Val Accuracy: 79.29%\n",
      "Starting training for the epoch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████| 546/546 [09:21<00:00,  1.03s/batch, accuracy=80.2, loss=0.618]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Train Loss: 0.6184, Train Accuracy: 80.20%, Val Loss: 0.5094, Val Accuracy: 83.34%\n",
      "Saved best model with Val Accuracy: 83.34%\n",
      "Starting training for the epoch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████| 546/546 [09:19<00:00,  1.02s/batch, accuracy=83.4, loss=0.492]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Train Loss: 0.4918, Train Accuracy: 83.39%, Val Loss: 0.4852, Val Accuracy: 83.30%\n",
      "Starting training for the epoch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████| 546/546 [09:18<00:00,  1.02s/batch, accuracy=86.3, loss=0.414]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 0.4136, Train Accuracy: 86.26%, Val Loss: 0.3623, Val Accuracy: 87.71%\n",
      "Saved best model with Val Accuracy: 87.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-86d27d53a67f>:44: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3623, Test Accuracy: 87.71%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Load datasets and DataLoaders\n",
    "    audio_dir = '/kaggle/input/urbansound8k'\n",
    "    file = '/kaggle/input/urbansound8k/UrbanSound8K.csv'\n",
    "\n",
    "    # Split dataset into train, validation, and test sets\n",
    "    train_dataset, val_dataset, test_dataset = create_datasets(audio_dir, file)\n",
    "\n",
    "    # Create DataLoaders for each set\n",
    "    train_loader, val_loader, test_loader = create_dataloaders(train_dataset, val_dataset, test_dataset)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "\n",
    "    # Initialize model, loss function, and optimizer\n",
    "    input_size = 40 + 32 + 128 + 1 + 1  # Features for MFCC, Chroma, Mel, ZCR, RMS\n",
    "    num_classes = len(train_dataset.label_encoder.classes_)  # Number of sound classes\n",
    "    model = AudioClassifierANN(input_size=input_size, num_classes=num_classes).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Initialize best validation accuracy and model checkpoint\n",
    "    best_val_acc = 0.0\n",
    "    best_model_path = '/kaggle/working/best_model_hamming.pth'  # Path where the best model will be saved\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 5\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_acc = test(model, val_loader, criterion, device)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.2f}%')\n",
    "\n",
    "        # Save the model if it has better validation accuracy\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f'Saved best model with Val Accuracy: {val_acc:.2f}%')\n",
    "\n",
    "    # Load the best model for final evaluation\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    model.to(device)\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    test_loss, test_acc = test(model, test_loader, criterion, device)\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 500970,
     "sourceId": 928025,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
